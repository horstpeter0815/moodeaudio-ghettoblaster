#!/usr/bin/env bash
################################################################################
# AI / RAG Tooling (GhettoAI)
#
# Purpose:
# - Verify local AI stack (Ollama + Open WebUI)
# - Prepare/refresh a clean RAG upload bundle manifest from rag-upload-files/
# - Auto-upload files to Open WebUI Knowledge Base via API
#
# Notes:
# - "Training" here means RAG knowledge ingestion in Open WebUI (not finetuning).
################################################################################

set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "$SCRIPT_DIR/.." && pwd)"
RAG_DIR="$PROJECT_ROOT/rag-upload-files"
WEBUI_URL="http://localhost:3000"
WEBUI_API="${WEBUI_URL}/api/v1"

# Default KB name (change if you rename it in Open WebUI)
KB_NAME="GhettoAI"

usage() {
  cat <<'EOF'
Usage:
  ./tools/ai.sh --verify
  ./tools/ai.sh --openwebui
  ./tools/ai.sh --manifest
  ./tools/ai.sh --upload [--token <jwt>]

Commands:
  --verify     Run existing AI setup verification (Ollama + Docker + Open WebUI + RAG files)
  --openwebui  Check whether Open WebUI is reachable (HTTP 200 expected)
  --manifest   Regenerate rag-upload-files/FILE_LIST.txt and rag-upload-files/MANIFEST.md
  --upload     Upload all rag-upload-files/* into Open WebUI KB "GhettoAI"
               (requires --token OR OPENWEBUI_TOKEN env var)
  --status     Check if KB needs refresh (compares last upload vs file changes)

Environment:
  OPENWEBUI_TOKEN  JWT token from Open WebUI (localStorage.token in browser)
EOF
}

# Tracking file for last successful upload
LAST_UPLOAD_FILE="$PROJECT_ROOT/.ghettoai-last-upload"

require_rag_dir() {
  if [ ! -d "$RAG_DIR" ]; then
    echo "‚ùå Missing: $RAG_DIR"
    echo "   Expected RAG corpus to exist. Aborting."
    exit 1
  fi
}

cmd_verify() {
  "$SCRIPT_DIR/test/VERIFY_AI_SETUP.sh"
}

cmd_openwebui() {
  if curl -sS -m 3 -o /dev/null -w "%{http_code}" "$WEBUI_URL" | grep -q '^200$'; then
    echo "‚úÖ Open WebUI reachable at $WEBUI_URL"
  else
    echo "‚ùå Open WebUI not reachable at $WEBUI_URL"
    echo "   Tip: run ./tools/test.sh --verify"
    exit 1
  fi
}

write_file_list() {
  # Create stable, deterministic list for upload review.
  (cd "$RAG_DIR" && find . -type f ! -name "FILE_LIST.txt" ! -name ".DS_Store" | sort) > "$RAG_DIR/FILE_LIST.txt"
}

count_dir_files() {
  local rel="$1"
  if [ -d "$RAG_DIR/$rel" ]; then
    find "$RAG_DIR/$rel" -type f ! -name ".DS_Store" | wc -l | tr -d ' '
  else
    echo "0"
  fi
}

cmd_manifest() {
  require_rag_dir
  write_file_list

  local total
  total="$(grep -c '^\./' "$RAG_DIR/FILE_LIST.txt" || true)"

  local n_docs n_cfg n_scripts n_src n_web n_v10
  n_docs="$(count_dir_files documentation)"
  n_cfg="$(count_dir_files configs)"
  n_scripts="$(count_dir_files scripts)"
  n_src="$(count_dir_files source-code)"
  n_web="$(count_dir_files web-interface)"
  n_v10="$(count_dir_files v1.0-docs)"

  cat > "$RAG_DIR/MANIFEST.md" <<EOF
# GhettoAI RAG Upload Manifest

**Generated:** $(date "+%Y-%m-%d %H:%M:%S")  
**Corpus root:** \`$RAG_DIR\`  
**Total files:** **$total**

## Recommended upload order (Open WebUI ‚Üí Knowledge)

1. **v1.0 docs (ground truth)**
   - \`rag-upload-files/v1.0-docs/\` (**$n_v10** files)
2. **Project documentation**
   - \`rag-upload-files/documentation/\` (**$n_docs** files)
3. **Key configs (boot, ALSA, NetworkManager, systemd)**
   - \`rag-upload-files/configs/\` (**$n_cfg** files)
4. **Scripts (fix + deploy + diagnostics)**
   - \`rag-upload-files/scripts/\` (**$n_scripts** files)
5. **Source code (moOde web + wizard backend)**
   - \`rag-upload-files/source-code/\` (**$n_src** files)
6. **Web interface pages (templates + pages)**
   - \`rag-upload-files/web-interface/\` (**$n_web** files)

## Suggested ‚ÄúGhettoAI‚Äù system prompt (copy/paste)

- You are **GhettoAI** for a custom moOde build on Raspberry Pi 5.
- Prefer **toolbox scripts** in \`tools/\` first; avoid creating root scripts.
- When giving commands, always use \`cd ~/moodeaudio-cursor && ...\`.
- Assume: display Waveshare 7.9" HDMI rotated to 1280x400, audio HiFiBerry AMP100, ethernet static 192.168.10.2.

## Notes

- \`FILE_LIST.txt\` is regenerated by \`./tools/ai.sh --manifest\`.
- If you change configs/scripts/source, rerun \`--manifest\` before uploading again.
EOF

  echo "‚úÖ Wrote:"
  echo "   - $RAG_DIR/FILE_LIST.txt"
  echo "   - $RAG_DIR/MANIFEST.md"
}

################################################################################
# --upload: full automated upload to Open WebUI KB
################################################################################

cmd_upload() {
  require_rag_dir

  # Get token from argument or env
  local token="${OPENWEBUI_TOKEN:-}"
  shift || true
  while [[ $# -gt 0 ]]; do
    case "$1" in
      --token)
        token="$2"
        shift 2
        ;;
      *)
        echo "‚ùå Unknown upload option: $1"
        exit 1
        ;;
    esac
  done

  if [ -z "$token" ]; then
    echo "‚ùå Missing Open WebUI token."
    echo "   Provide via --token <jwt> or set OPENWEBUI_TOKEN env var."
    echo ""
    echo "   To get the token:"
    echo "     1. Open $WEBUI_URL in your browser"
    echo "     2. Open DevTools ‚Üí Console"
    echo "     3. Run: localStorage.token"
    echo "     4. Copy the value (starts with eyJ...)"
    exit 1
  fi

  # Resolve KB ID by name
  echo "üîç Looking up Knowledge Base '$KB_NAME'..."
  local kb_json kb_id
  kb_json="$(curl -sS -H "Authorization: Bearer $token" -H 'Accept: application/json' "$WEBUI_API/knowledge/")"
  kb_id="$(echo "$kb_json" | python3 -c "import sys,json; items=json.load(sys.stdin).get('items',[]); print(next((k['id'] for k in items if k['name']=='$KB_NAME'),''))")"

  if [ -z "$kb_id" ]; then
    echo "‚ùå Knowledge Base '$KB_NAME' not found in Open WebUI."
    echo "   Create it manually first: $WEBUI_URL ‚Üí Knowledge ‚Üí New"
    exit 1
  fi

  echo "   ‚Üí KB ID: $kb_id"

  # Invoke Python uploader (inline)
  echo ""
  echo "üì§ Uploading files to '$KB_NAME'..."
  python3 - "$token" "$kb_id" "$RAG_DIR" "$WEBUI_API" <<'PYEOF'
import json, os, sys, time
from pathlib import Path
import urllib.request, urllib.error

TOKEN, KB_ID, RAG_DIR, BASE = sys.argv[1], sys.argv[2], Path(sys.argv[3]), sys.argv[4]
SKIP_NAMES = {".DS_Store", "FILE_LIST.txt"}

def multipart(boundary, name, filename, data):
    pre = (
        f"--{boundary}\r\n"
        f'Content-Disposition: form-data; name="{name}"; filename="{filename}"\r\n'
        f"Content-Type: application/octet-stream\r\n\r\n"
    ).encode()
    return pre + data + f"\r\n--{boundary}--\r\n".encode()

def upload_file(path, filename):
    boundary = "----ghettoai-upload-boundary"
    body = multipart(boundary, "file", filename, path.read_bytes())
    req = urllib.request.Request(
        f"{BASE}/files/",
        data=body, method="POST",
        headers={
            "Accept": "application/json",
            "Authorization": f"Bearer {TOKEN}",
            "Content-Type": f"multipart/form-data; boundary={boundary}",
        },
    )
    with urllib.request.urlopen(req, timeout=120) as r:
        return json.loads(r.read())

def get_file(fid):
    req = urllib.request.Request(f"{BASE}/files/{fid}", headers={"Accept": "application/json", "Authorization": f"Bearer {TOKEN}"})
    with urllib.request.urlopen(req, timeout=60) as r:
        return json.loads(r.read())

def wait_complete(fid, timeout=90):
    t0 = time.time()
    while True:
        st = (get_file(fid).get("data") or {}).get("status")
        if st == "completed": return
        if st == "failed": raise RuntimeError("processing failed")
        if time.time() - t0 > timeout: raise RuntimeError("timeout")
        time.sleep(0.3)

def add_to_kb(fid):
    payload = json.dumps({"file_id": fid}).encode()
    req = urllib.request.Request(
        f"{BASE}/knowledge/{KB_ID}/file/add",
        data=payload, method="POST",
        headers={"Accept": "application/json", "Authorization": f"Bearer {TOKEN}", "Content-Type": "application/json"},
    )
    with urllib.request.urlopen(req, timeout=120) as r:
        return json.loads(r.read())

def list_kb_filenames():
    names, page = set(), 1
    while True:
        req = urllib.request.Request(f"{BASE}/knowledge/{KB_ID}/files?page={page}", headers={"Accept": "application/json", "Authorization": f"Bearer {TOKEN}"})
        with urllib.request.urlopen(req, timeout=60) as r:
            out = json.loads(r.read())
        for it in out.get("items", []):
            nm = it.get("filename") or (it.get("meta") or {}).get("name")
            if nm: names.add(nm)
        if page * 30 >= out.get("total", 0): break
        page += 1
    return names

existing = list_kb_filenames()
paths = sorted([p for p in RAG_DIR.rglob("*") if p.is_file() and p.name not in SKIP_NAMES and p.suffix.lower() != ".zip"], key=str)

print(f"KB already has {len(existing)} file(s). Upload candidates: {len(paths)}")

ok, skip, fail = 0, 0, 0
for idx, p in enumerate(paths, 1):
    if p.name in existing:
        skip += 1
        continue
    try:
        up = upload_file(p, str(p.relative_to(RAG_DIR)))
        fid = up["id"]
        wait_complete(fid)
        add_to_kb(fid)
        ok += 1
        if ok % 20 == 0 or idx == 1:
            print(f"[{idx}/{len(paths)}] ok={ok} skip={skip} fail={fail}")
        time.sleep(0.05)
    except Exception as e:
        fail += 1
        print(f"FAIL {p}: {e}")

print(f"‚úÖ Done: ok={ok} skip={skip} fail={fail}")
PYEOF

  # Record successful upload timestamp
  date +%s > "$LAST_UPLOAD_FILE"
  echo "   (Recorded upload timestamp in .ghettoai-last-upload)"

  echo ""
  echo "üéâ Upload complete. Open $WEBUI_URL ‚Üí Knowledge ‚Üí $KB_NAME to verify."
}

################################################################################
# --status: check if KB refresh is recommended
################################################################################

cmd_status() {
  require_rag_dir

  echo "üìä GhettoAI Knowledge Base Status"
  echo ""

  # Check last upload
  local last_upload_ts=0
  local last_upload_str="never"
  if [ -f "$LAST_UPLOAD_FILE" ]; then
    last_upload_ts="$(cat "$LAST_UPLOAD_FILE")"
    last_upload_str="$(date -r "$last_upload_ts" "+%Y-%m-%d %H:%M" 2>/dev/null || date -d "@$last_upload_ts" "+%Y-%m-%d %H:%M" 2>/dev/null || echo "unknown")"
  fi
  echo "   Last upload: $last_upload_str"

  # Check newest file in rag-upload-files
  local newest_file newest_ts=0
  newest_file="$(find "$RAG_DIR" -type f ! -name ".DS_Store" ! -name "FILE_LIST.txt" -printf '%T@ %p\n' 2>/dev/null | sort -rn | head -1 | cut -d' ' -f2- || true)"
  if [ -z "$newest_file" ]; then
    # macOS fallback (no -printf)
    newest_file="$(find "$RAG_DIR" -type f ! -name ".DS_Store" ! -name "FILE_LIST.txt" -exec stat -f '%m %N' {} \; 2>/dev/null | sort -rn | head -1 | cut -d' ' -f2- || true)"
    if [ -n "$newest_file" ]; then
      newest_ts="$(stat -f '%m' "$newest_file" 2>/dev/null || echo 0)"
    fi
  else
    newest_ts="$(stat -c '%Y' "$newest_file" 2>/dev/null || stat -f '%m' "$newest_file" 2>/dev/null || echo 0)"
  fi

  local newest_str="unknown"
  if [ "$newest_ts" -gt 0 ]; then
    newest_str="$(date -r "$newest_ts" "+%Y-%m-%d %H:%M" 2>/dev/null || date -d "@$newest_ts" "+%Y-%m-%d %H:%M" 2>/dev/null || echo "unknown")"
  fi
  echo "   Newest file: $newest_str"
  [ -n "$newest_file" ] && echo "                (${newest_file#$RAG_DIR/})"

  # Calculate staleness
  local now days_since_upload files_changed
  now="$(date +%s)"
  if [ "$last_upload_ts" -gt 0 ]; then
    days_since_upload=$(( (now - last_upload_ts) / 86400 ))
  else
    days_since_upload=999
  fi

  if [ "$newest_ts" -gt "$last_upload_ts" ]; then
    files_changed="yes"
  else
    files_changed="no"
  fi

  echo ""
  echo "   Days since upload: $days_since_upload"
  echo "   Files changed since: $files_changed"

  # Recommendation
  echo ""
  if [ "$files_changed" = "yes" ]; then
    echo "‚ö†Ô∏è  Recommendation: REFRESH NEEDED"
    echo "   Files have changed since last upload."
    echo ""
    echo "   Run: OPENWEBUI_TOKEN='<token>' ./tools/ai.sh --upload"
  elif [ "$days_since_upload" -gt 30 ]; then
    echo "üí° Recommendation: Consider refreshing (>30 days old)"
    echo ""
    echo "   Run: OPENWEBUI_TOKEN='<token>' ./tools/ai.sh --upload"
  else
    echo "‚úÖ Knowledge Base is up to date."
  fi
}

################################################################################

main() {
  if [ $# -lt 1 ]; then
    usage
    exit 1
  fi

  local cmd="$1"
  shift || true

  case "$cmd" in
    --verify) cmd_verify ;;
    --openwebui) cmd_openwebui ;;
    --manifest) cmd_manifest ;;
    --upload) cmd_upload "$@" ;;
    --status) cmd_status ;;
    -h|--help) usage ;;
    *)
      echo "‚ùå Unknown option: $cmd"
      echo ""
      usage
      exit 1
      ;;
  esac
}

main "$@"


